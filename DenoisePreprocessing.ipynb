{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59856227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure\n",
    "from statistics import median, mean\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "from torchsummary import summary\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import sys\n",
    "path = \"/study/mrphys/skunkworks/kk/mriUnet\"\n",
    "sys.path.insert(0,path)\n",
    "import unet\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "from sklearn.model_selection import KFold as kf\n",
    "import os\n",
    "\n",
    "allImages = sorted(glob(\"/study/mrphys/skunkworks/training_data//mover01/*/\", recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "966850b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getComplexSlices(path):\n",
    "\n",
    "    with h5py.File(path,'r') as hf:\n",
    "        prefix = 'C_000_0'\n",
    "        imagestackReal = []\n",
    "        imagestackImag = []\n",
    "        for i in range(10):\n",
    "            n = prefix + str(i).zfill(2)\n",
    "            image = hf['Images'][n]\n",
    "            imagestackReal.append(np.array(image['real']))\n",
    "            imagestackImag.append(np.array(image['imag']))\n",
    "            if i==0:\n",
    "                normScale = np.abs(np.array(image['real']+image['real']*1j)).max()\n",
    "        imagestackReal = np.array(imagestackReal)/normScale\n",
    "        imagestackImag = np.array(imagestackImag)/normScale\n",
    "        \n",
    "    return imagestackReal+imagestackImag*1j\n",
    "\n",
    "class mriSliceDataset(Dataset):\n",
    "    def __init__(self, sample):\n",
    "        self.originalPath = []\n",
    "        self.accelPath = [] \n",
    "\n",
    "        allImages = sorted(glob(\"/study/mrphys/skunkworks/training_data//mover01/*/\", recursive=True))\n",
    "        folderName  = allImages[sample]\n",
    "        self.originalPath = folderName + 'processed_data/C.h5'\n",
    "        self.accelPath = folderName +'processed_data/acc_2min/C.h5'\n",
    "        \n",
    "        self.originalFile = getComplexSlices(self.originalPath)\n",
    "        self.accelFile = getComplexSlices(self.accelPath)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index<256:\n",
    "            return self.accelFile[index,:,:], self.originalFile[index,:,:]\n",
    "        elif index<512:\n",
    "            return self.accelFile[:,index,:], self.originalFile[:,index,:]\n",
    "        else:\n",
    "            return self.accelFile[:,:,index], self.originalFile[:,:,index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21a39dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 65/65 [14:16<00:00, 13.17s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(allImages))):\n",
    "    dataset = mriSliceDataset(i)\n",
    "    with open(f'/scratch/mrphys/pickled/dataset_{i}.pickle', 'wb') as f:\n",
    "        pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ac2f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 65/65 [43:17<00:00, 39.96s/it]\n"
     ]
    }
   ],
   "source": [
    "def getComplexSlices(path):\n",
    "\n",
    "    with h5py.File(path,'r') as hf:\n",
    "        prefix = 'C_000_0'\n",
    "        imagestackReal = []\n",
    "        imagestackImag = []\n",
    "        for i in range(10):\n",
    "            n = prefix + str(i).zfill(2)\n",
    "            image = hf['Images'][n]\n",
    "            normScale = np.abs(np.array(image['real']+image['imag']*1j)).max()\n",
    "            imagestackReal.append(np.array(image['real'])/normScale)\n",
    "            imagestackImag.append(np.array(image['imag'])/normScale)\n",
    "        imagestackReal = np.array(imagestackReal)\n",
    "        imagestackImag = np.array(imagestackImag)\n",
    "        \n",
    "    return imagestackReal+imagestackImag*1j\n",
    "\n",
    "class mriSliceDataset(Dataset):\n",
    "    def __init__(self, sample):\n",
    "        self.originalPath = []\n",
    "        self.accelPath = [] \n",
    "\n",
    "        allImages = sorted(glob(\"/study/mrphys/skunkworks/training_data//mover01/*/\", recursive=True))\n",
    "        folderName  = allImages[sample]\n",
    "        self.originalPath = folderName + 'processed_data/C.h5'\n",
    "        self.accelPath = folderName +'processed_data/acc_2min/C.h5'\n",
    "        \n",
    "        self.originalFile = getComplexSlices(self.originalPath)\n",
    "        self.accelFile = getComplexSlices(self.accelPath)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index<256:\n",
    "            return self.accelFile[index,:,:], self.originalFile[index,:,:]\n",
    "        elif index<512:\n",
    "            return self.accelFile[:,index,:], self.originalFile[:,index,:]\n",
    "        else:\n",
    "            return self.accelFile[:,:,index], self.originalFile[:,:,index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 768\n",
    "    \n",
    "for i in tqdm(range(len(allImages))):\n",
    "    dataset = mriSliceDataset(i)\n",
    "    with open(f'/scratch/mrphys/pickled/ddpm_dataset_{i}.pickle', 'wb') as f:\n",
    "        pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a866c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
