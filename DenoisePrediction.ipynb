{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3fb010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from statistics import median, mean\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,\"/study/mrphys/skunkworks/kk/mriUnet\")\n",
    "import unet\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import KFold as kf\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd3073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "allImages = sorted(glob(\"/study/mrphys/skunkworks/training_data//mover01/*/\", recursive=True))[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b909de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getComplexSlices(path):\n",
    "\n",
    "    with h5py.File(path,'r') as hf:\n",
    "        prefix = 'C_000_0'\n",
    "        imagestackReal = []\n",
    "        imagestackImag = []\n",
    "        for i in range(10):\n",
    "            n = prefix + str(i).zfill(2)\n",
    "            image = hf['Images'][n]\n",
    "            imagestackReal.append(np.array(image['real']))\n",
    "            imagestackImag.append(np.array(image['imag']))\n",
    "            if i==0:\n",
    "                normScale = np.abs(np.array(image['real']+image['real']*1j)).max()\n",
    "        imagestackReal = np.array(imagestackReal)/normScale\n",
    "        imagestackImag = np.array(imagestackImag)/normScale\n",
    "        \n",
    "    return imagestackReal+imagestackImag*1j, normScale\n",
    "\n",
    "class mriNoisyDataset(Dataset):\n",
    "    def __init__(self, sample):\n",
    "        self.originalPath = []\n",
    "        self.accelPath = [] \n",
    "\n",
    "        allImages = sorted(glob(\"/study/mrphys/skunkworks/training_data//mover01/*/\", recursive=True))[0:40]\n",
    "        folderName  = allImages[sample]\n",
    "        self.accelPath = folderName +'processed_data/acc_2min/C.h5'\n",
    "        self.accelFile, self.scale = getComplexSlices(self.accelPath)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index<256:\n",
    "            return self.accelFile[:,index,:,:]\n",
    "        elif index<512:\n",
    "            index = index-256\n",
    "            return self.accelFile[:,:,index,:]\n",
    "        else:\n",
    "            index = index-512\n",
    "            return self.accelFile[:,:,:,index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c762dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset, device = 5):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    X = []\n",
    "    Y = []\n",
    "    Z = []\n",
    "    for i, noisy in enumerate(dataset):\n",
    "        noisy = torch.tensor(noisy).to(device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            p = model(noisy).cpu().numpy() * dataset.scale\n",
    "            if i<256:\n",
    "                X.append(p)\n",
    "            elif i<512:\n",
    "                Y.append(p)\n",
    "            else:\n",
    "                Z.append(p)\n",
    "                \n",
    "    return np.vstack(X).transpose(1,0,2,3), np.vstack(Y).transpose(1,2,0,3), np.vstack(Z).transpose(1,2,3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a282d241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop amount [(-4, -4, -4, -4), (-16, -16, -16, -16), (-40, -40, -40, -40)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████████████████████████████████████████▏                         | 9/13 [04:47<02:07, 31.97s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [67], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/study/mrphys/skunkworks/kk/outputs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/weights/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_BEST.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m tqdm(test_index):\n\u001b[0;32m---> 21\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mmriNoisyDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     X, Y, Z \u001b[38;5;241m=\u001b[39m predict(model, dataset)\n\u001b[1;32m     23\u001b[0m     pred \u001b[38;5;241m=\u001b[39m (X\u001b[38;5;241m+\u001b[39mY\u001b[38;5;241m+\u001b[39mZ)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m\n",
      "Cell \u001b[0;32mIn [19], line 25\u001b[0m, in \u001b[0;36mmriNoisyDataset.__init__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelPath \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m     24\u001b[0m allImages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/study/mrphys/skunkworks/training_data//mover01/*/\u001b[39m\u001b[38;5;124m\"\u001b[39m, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m40\u001b[39m]\n\u001b[0;32m---> 25\u001b[0m folderName  \u001b[38;5;241m=\u001b[39m \u001b[43mallImages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelPath \u001b[38;5;241m=\u001b[39m folderName \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_data/acc_2min/C.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelFile, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m getComplexSlices(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelPath)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "kfsplitter = kf(n_splits=folds, shuffle=True, random_state=69420)\n",
    "for i, (train_index, test_index) in enumerate(kfsplitter.split(allImages)):\n",
    "    fold = i+1\n",
    "    model = unet.UNet(\n",
    "        10,\n",
    "        10,\n",
    "        f_maps=32,\n",
    "        layer_order=['separable convolution', 'relu'],\n",
    "        depth=4,\n",
    "        layer_growth=2.0,\n",
    "        residual=True,\n",
    "        complex_input=True,\n",
    "        complex_kernel=True,\n",
    "        ndims=2,\n",
    "        padding=1\n",
    "    )\n",
    "    name = f'fullDenoiser_{fold}'\n",
    "    model.load_state_dict(torch.load(f'/study/mrphys/skunkworks/kk/outputs/{name}/weights/{name}_BEST.pth'))\n",
    "    for index in tqdm(test_index):\n",
    "        dataset = mriNoisyDataset(index)\n",
    "        X, Y, Z = predict(model, dataset)\n",
    "        pred = (X+Y+Z)/3\n",
    "        np.save(f'pred/denoised_{index}.npy',np.array(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b616d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
